---
title: "Neural Network Analysis - Student Dropout Prediction"
author: "Person B"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(nnet)        # Simple neural network
# library(neuralnet) # Alternative package
# library(keras)     # Deep learning (if you want to use TensorFlow)
library(caret)       # For confusion matrix
```

# Neural Network Analysis

## Objective
Use neural networks to predict student dropout vs. graduation, leveraging the ability to capture complex non-linear interactions between features.

## Data Loading & Preprocessing

```{r load-data}
# Load data
data <- read.csv("../../data/preprocessed_data.csv", stringsAsFactors = TRUE)

# Filter for Graduate vs Dropout
nn_data <- data %>%
  filter(Target %in% c("Graduate", "Dropout")) %>%
  mutate(Target_binary = as.factor(ifelse(Target == "Graduate", "Graduate", "Dropout")))

# Select features (adjust based on your analysis)
nn_features <- c(
  "Curricular.units.1st.sem..approved.",
  "Curricular.units.1st.sem..grade.",
  "Curricular.units.2nd.sem..approved.",
  "Curricular.units.2nd.sem..grade.",
  "Tuition.fees.up.to.date",
  "Scholarship.holder",
  "Age.at.enrollment",
  "Admission.grade",
  "Debtor"
)

# Create modeling dataset
nn_model_data <- nn_data %>%
  select(all_of(nn_features), Target_binary) %>%
  na.omit()

# Normalize numeric features (important for neural networks!)
numeric_cols <- sapply(nn_model_data, is.numeric)
nn_model_data[, numeric_cols] <- scale(nn_model_data[, numeric_cols])

cat("Dataset size:", nrow(nn_model_data), "students\n")
cat("Class distribution:\n")
table(nn_model_data$Target_binary)
```

## Train/Test Split

```{r train-test-split}
set.seed(123)
train_idx <- createDataPartition(nn_model_data$Target_binary, p = 0.8, list = FALSE)
train_nn <- nn_model_data[train_idx, ]
test_nn <- nn_model_data[-train_idx, ]

cat("Training set:", nrow(train_nn), "samples\n")
cat("Test set:", nrow(test_nn), "samples\n")
```

## Model Training

### Option 1: Simple Neural Network with `nnet`

```{r train-nnet}
# Train neural network with one hidden layer
# size = number of hidden units, decay = regularization parameter
nn_model <- nnet(
  Target_binary ~ .,
  data = train_nn,
  size = 10,        # 10 hidden units
  decay = 0.01,     # Regularization
  maxit = 500,      # Maximum iterations
  trace = FALSE     # Don't print training progress
)

cat("Model trained successfully!\n")
cat("Hidden units:", nn_model$n[2], "\n")
cat("Weights:", length(nn_model$wts), "\n")
```

### Option 2: Neural Network with `neuralnet` (uncomment if you prefer)

```{r train-neuralnet, eval=FALSE}
# library(neuralnet)
# 
# # Create formula
# formula_nn <- as.formula(paste("Target_binary ~", paste(nn_features, collapse = " + ")))
# 
# # Train
# nn_model_alt <- neuralnet(
#   formula_nn,
#   data = train_nn,
#   hidden = c(10, 5),  # Two hidden layers
#   linear.output = FALSE,
#   threshold = 0.01
# )
# 
# plot(nn_model_alt)  # Visualize network
```

## Model Evaluation

```{r evaluate}
# Predictions on test set
pred_nn_class <- predict(nn_model, newdata = test_nn, type = "class")

# Confusion matrix
conf_matrix <- confusionMatrix(
  as.factor(pred_nn_class),
  test_nn$Target_binary,
  positive = "Graduate"
)

print(conf_matrix)
```

## Performance Metrics Summary

```{r performance-summary}
cat("=== Neural Network Performance ===\n\n")
cat("Accuracy:", round(conf_matrix$overall["Accuracy"], 3), "\n")
cat("Precision:", round(conf_matrix$byClass["Precision"], 3), "\n")
cat("Recall:", round(conf_matrix$byClass["Recall"], 3), "\n")
cat("F1-Score:", round(conf_matrix$byClass["F1"], 3), "\n")
cat("Balanced Accuracy:", round(conf_matrix$byClass["Balanced Accuracy"], 3), "\n")
```

## Confusion Matrix Visualization

```{r confusion-matrix-plot}
# Create confusion matrix dataframe
cm_df <- as.data.frame(conf_matrix$table)
names(cm_df) <- c("Prediction", "Reference", "Freq")

# Plot
ggplot(cm_df, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 8, color = "white", fontface = "bold") +
  scale_fill_gradient(low = "#3498DB", high = "#E74C3C") +
  labs(title = "Neural Network Confusion Matrix",
       x = "Actual Outcome", y = "Predicted Outcome") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Feature Importance (Optional - requires additional analysis)

```{r feature-importance, eval=FALSE}
# Note: Neural networks don't have straightforward feature importance
# You can use permutation importance or SHAP values
# For simplicity, you can report which features were used

cat("Top features used in model:\n")
cat(paste(nn_features, collapse = ", "), "\n")
```

## Key Findings & Interpretation

### Model Architecture
- **Input Layer:** 9 features (student characteristics and performance)
- **Hidden Layer:** 10 neurons with sigmoid activation
- **Output Layer:** Binary classification (Graduate vs. Dropout)
- **Regularization:** L2 penalty (decay = 0.01) to prevent overfitting

### Performance Highlights
**[Person B: Fill in your actual results]**
- Achieved XX% accuracy on test set
- High recall for graduates (XX%) - few false negatives
- Balanced performance across both classes

### Compared to Linear Models
Neural networks can capture:
- Non-linear relationships between features
- Complex interactions (e.g., age × grades × financial status)
- Threshold effects that linear models miss

### Business Insight
The neural network confirms findings from other models:
- 1st semester performance is critical
- Financial factors (tuition, scholarship) matter
- Non-linear patterns exist (e.g., students with mid-range grades face higher uncertainty)

### Limitations
- **Black box:** Less interpretable than linear models
- **Requires tuning:** Hidden layer size, learning rate, regularization
- **Data hungry:** Performs best with larger datasets

## Comparison with Other Models

| Model | Accuracy | Interpretability | Complexity |
|-------|----------|------------------|------------|
| Logistic Regression (GLM) | ~85% | High | Low |
| GAM | ~87% | Medium | Medium |
| **Neural Network** | **XX%** | **Low** | **High** |
| SVM | TBD | Medium | Medium |

### When to Use Neural Networks
- ✅ High accuracy is priority
- ✅ Large dataset available
- ✅ Complex interactions suspected
- ❌ Interpretability required
- ❌ Limited computational resources

## Conclusions

**Summary of NN findings:**
1. Neural network achieved competitive/superior accuracy compared to linear methods
2. Confirms importance of 1st semester performance and financial factors
3. Captures non-linear patterns that simpler models miss
4. Trade-off: Higher accuracy but less interpretability

**Practical Application:**
- Use NN for **prediction** in early warning system
- Use GLM/GAM for **interpretation** and stakeholder communication
- Ensemble approach: Combine both for robust predictions

---

**Person B: When copying to main report:**
1. Remove the YAML header (keep only the content)
2. Adjust section numbering to match main report
3. Update "XX%" placeholders with your actual results
4. Paste into Section 8 of MASTER_REPORT.rmd
